---
---

@article{MTAP.82.2023,
  abbr={MTAP},
  title={A novel multi-modal depression detection approach based on mobile crowd sensing and task-based mechanisms},
  author={Ravi Prasad Thati, Abhishek Singh Dhadwal, Praveen Kumar & Sainaba P},
  abstract={Depression has become a global concern, and COVID-19 also has caused a big surge in its incidence. Broadly, there are two primary methods of detecting depression: Task-based and Mobile Crowd Sensing (MCS) based methods. These two approaches, when integrated, can complement each other. This paper proposes a novel approach for depression detection that combines real-time MCS and task-based mechanisms. We aim to design an end-to-end machine learning pipeline, which involves multimodal data collection, feature extraction, feature selection, fusion, and classification to distinguish between depressed and non-depressed subjects. For this purpose, we created a real-world dataset of depressed and non-depressed subjects. We experimented with: various features from multi-modalities, feature selection techniques, fused features, and machine learning classifiers such as Logistic Regression, Support Vector Machines (SVM), etc. for classification. Our findings suggest that combining features from multiple modalities perform better than any single data modality, and the best classification accuracy is achieved when features from all three data modalities are fused. Feature selection method based on Pearsonâ€™s correlation coefficients improved the accuracy in comparison with other methods. Also, SVM yielded the best accuracy of 86%. Our proposed approach was also applied on benchmarking dataset, and results demonstrated that the multimodal approach is advantageous in performance with state-of-the-art depression recognition techniques.},
  journal={Multimedia Tools and Applications},
  volume={82},
  pages={4787--4820},
  year={2022},
  month={April},
  publisher={Springer},
  doi={10.1007/s11042-022-12315-2},
  url={https://link.springer.com/article/10.1007/s11042-022-12315-2},
  html={https://link.springer.com/content/pdf/10.1007/s11042-022-12315-2.pdf},
  dimensions={true},
  google_scholar_id={IRzZeuUAAAAJ},
  selected={true}
}

@article{IJAIT.82.2023,
  abbr={IJAIT},
  title={Multimodal Depression Detection: Using Fusion Strategies with Smart Phone Usage and Audio-visual Behavior},
  author={Ravi Prasad Thati, Abhishek Singh Dhadwal, Praveen Kumar & Sainaba P},
  abstract={The problem of detecting depression is multi-faceted because of variability in depressive symptoms caused by individual differences. The variations can be seen in historical information (like decreased physical activity etc.) and also in verbal/non-verbal behaviors (like lower pitch, downward eye gaze etc.). The primary goal of this research is to develop a novel classification system for diagnosing depression that considers both historical information and also verbal/non-verbal behaviors. For this purpose, we created a realworld multimodal dataset of depressed and non-depressed subjects with fourteen-day real-time smartphone usage records and audio-visual recordings. We extracted numerous features related to physiological/physical activity from smartphone usage records to capture historical information and features like pitch and eye gaze (verbal and non-verbal manifestations) from audio-visual clues. We experimented with early fusion using Decision trees classifier (along with several feature selection strategies) and Support Vector Machine (SVM) classifier with several late fusion methods. Then, we conducted a comparative study among both fusion strategies. Our findings showed that SVM classifier using late fusion strategy achieves best accuracy of 89%. In addition, a popular benchmarking multimodal dataset (DAIC-WOZ database) is used to further validate the effectiveness of our approach by fusing multi-faceted feature vectors for depression detection.},
  journal={Multimedia Tools and Applications},
  volume={32},
  pages={4787--4820},
  year={2023},
  month={April},
  publisher={World Scientific},
  doi={10.1142/S0218213023400080},
  url={https://www.worldscientific.com/doi/10.1142/S0218213023400080},
  html={https://www.worldscientific.com/doi/reader/10.1142/S0218213023400080},
  dimensions={true},
  google_scholar_id={IRzZeuUAAAAJ},
  selected={true}
}
